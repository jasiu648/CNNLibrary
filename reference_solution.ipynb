{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_and_accuracy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Statistics: mean  # standard library\n",
    "function loss_and_accuracy(model, data)\n",
    "    (x,y) = only(loader(data; batchsize=length(data)))\n",
    "    ŷ = model(x)\n",
    "    loss = Flux.logitcrossentropy(ŷ, y)  # did not include softmax in the model\n",
    "    acc = round(100 * mean(Flux.onecold(ŷ) .== Flux.onecold(y)); digits=2)\n",
    "    (; loss, acc, split=data.split)  # return a NamedTuple\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((3, 3), 1 => 6, relu),           \u001b[90m# 60 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Conv((3, 3), 6 => 16, relu),          \u001b[90m# 880 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Flux.flatten,\n",
       "  Dense(400 => 84, relu),               \u001b[90m# 33_684 parameters\u001b[39m\n",
       "  Dense(84 => 10),                      \u001b[90m# 850 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 8 arrays, \u001b[39m35_474 parameters, 139.773 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Opracowane na podstawie https://github.com/FluxML/model-zoo/blob/3e91af32ebfad628b616618b11bfff2f9f519bec/vision/conv_mnist/conv_mnist.jl\n",
    "using MLDatasets, Flux\n",
    "train_data = MLDatasets.MNIST(split=:train)\n",
    "test_data  = MLDatasets.MNIST(split=:test)\n",
    "\n",
    "function loader(data; batchsize::Int=1)\n",
    "    x4dim = reshape(data.features, 28, 28, 1, :) # insert trivial channel dim\n",
    "    yhot  = Flux.onehotbatch(data.targets, 0:9)  # make a 10×60000 OneHotMatrix\n",
    "    Flux.DataLoader((x4dim, yhot); batchsize, shuffle=true)\n",
    "end\n",
    "\n",
    "net = Chain(\n",
    "    Conv((3, 3), 1 => 6,  relu),\n",
    "    MaxPool((2, 2)),\n",
    "    Conv((3, 3), 6 => 16, relu),\n",
    "    MaxPool((2, 2)),\n",
    "    Flux.flatten,\n",
    "    Dense(400 => 84, relu), \n",
    "    Dense(84 => 10, identity),\n",
    ")\n",
    "\n",
    "#= ew. prostsza architektura:\n",
    "\n",
    "net = Chain(\n",
    "    Conv((3, 3), 1 => 6,  relu, bias=false),\n",
    "    MaxPool((2, 2)),\n",
    "    Flux.flatten,\n",
    "    Dense(13*13*6 => 84, relu, bias=false), \n",
    "    Dense(84 => 10, identity, bias=false)\n",
    ")\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400×1 Matrix{Float32}:\n",
       " 0.0\n",
       " 0.07217326\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.045555223\n",
       " 0.026632763\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.51805997\n",
       " 0.26482785\n",
       " 0.545838\n",
       " 0.5025322\n",
       " 0.2411429\n",
       " 0.5090034\n",
       " 0.32289258\n",
       " 0.40637982\n",
       " 0.20456274"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1, y1 = first(loader(train_data)); # (28×28×1×1 Array{Float32, 3}, 10×1 OneHotMatrix(::Vector{UInt32}))\n",
    "y1hat = net(x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show hcat(Flux.onecold(y1hat, 0:9), Flux.onecold(y1, 0:9))\n",
    "\n",
    "@show loss_and_accuracy(net, test_data);  # accuracy about 10%, before training\n",
    "\n",
    "train_log = []\n",
    "settings = (;\n",
    "    eta = 1e-2,\n",
    "    epochs = 3,\n",
    "    batchsize = 100,\n",
    ")\n",
    "\n",
    "opt_state = Flux.setup(Descent(settings.eta), net);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show hcat(Flux.onecold(y1hat, 0:9), Flux.onecold(y1, 0:9))\n",
    "\n",
    "@show loss_and_accuracy(net, test_data);  # accuracy about 10%, before training\n",
    "\n",
    "train_log = []\n",
    "settings = (;\n",
    "    eta = 1e-2,\n",
    "    epochs = 3,\n",
    "    batchsize = 100,\n",
    ")\n",
    "\n",
    "opt_state = Flux.setup(Descent(settings.eta), net);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.676747 seconds (440.60 k allocations: 8.012 GiB, 5.27% gc time, 3.72% compilation time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: 1\n",
      "│   acc = 10.62\n",
      "│   test_acc = 10.72\n",
      "└ @ Main d:\\Projects\\CNNLibrary\\reference_solution.ipynb:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.037630 seconds (303.35 k allocations: 8.004 GiB, 5.22% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: 2\n",
      "│   acc = 10.62\n",
      "│   test_acc = 10.72\n",
      "└ @ Main d:\\Projects\\CNNLibrary\\reference_solution.ipynb:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.939930 seconds (303.35 k allocations: 8.004 GiB, 5.50% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: 3\n",
      "│   acc = 10.62\n",
      "│   test_acc = 10.72\n",
      "└ @ Main d:\\Projects\\CNNLibrary\\reference_solution.ipynb:10\n"
     ]
    }
   ],
   "source": [
    "for epoch in 1:settings.epochs\n",
    "    @time for (x,y) in loader(train_data, batchsize=settings.batchsize)\n",
    "        grads = Flux.gradient(model -> Flux.logitcrossentropy(model(x), y), net)\n",
    "        sizeof(grads)\n",
    "        #Flux.update!(opt_state, net, grads[1])\n",
    "    end\n",
    "    \n",
    "    loss, acc, _ = loss_and_accuracy(net, train_data)\n",
    "    test_loss, test_acc, _ = loss_and_accuracy(net, test_data)\n",
    "    @info epoch acc test_acc\n",
    "    nt = (; epoch, loss, acc, test_loss, test_acc) \n",
    "    push!(train_log, nt)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Any}:\n",
       " (epoch = 1, loss = 2.3029556f0, acc = 10.62, test_loss = 2.3041186f0, test_acc = 10.72)\n",
       " (epoch = 2, loss = 2.3029556f0, acc = 10.62, test_loss = 2.3041186f0, test_acc = 10.72)\n",
       " (epoch = 3, loss = 2.3029556f0, acc = 10.62, test_loss = 2.3041186f0, test_acc = 10.72)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
